{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "#from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import optparse\n",
    "import os.path as osp\n",
    "import math\n",
    "import torch_geometric\n",
    "import torch\n",
    "import sys\n",
    "from torch_geometric.data import Data\n",
    "import glob\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import torch.jit as jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt=torch.load(\"/grid_mnt/data__data.polcms/cms/sghosh/NEWPID_TICLDUMPER_DATA/ntup_pho_18082024/data_499.pt\")\n",
    "# np.unique(tt[0].clus2d_feat[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# clus2d_feats = np.stack((ak.to_numpy(sel_clusters[ts].position_x),\n",
    "#                          ak.to_numpy(sel_clusters[ts].position_y),\n",
    "#                          ak.to_numpy(sel_clusters[ts].position_z),\n",
    "#                          ak.to_numpy(sel_clusters[ts].energy),\n",
    "#                          ak.to_numpy(sel_clusters[ts].cluster_time),\n",
    "#                          ak.to_numpy(sel_clusters[ts].cluster_layer_id))).T\n",
    "\n",
    "#                     #print(clus2d_feats.shape)\n",
    "# clus3d_feats = np.stack((sel_tseta[ts][0],\n",
    "#                          sel_tsphi[ts][0],\n",
    "#                          sel_tsen[ts][0],\n",
    "#                          sel_tst[ts][0],\n",
    "#                          min(ak.to_numpy(sel_clusters[ts].cluster_layer_id)),\n",
    "#                          max(ak.to_numpy(sel_clusters[ts].cluster_layer_id)))).T\n",
    "# gun_feats = np.stack((sel_cpeta[ts][0],\n",
    "#                       sel_cpphi[ts][0],\n",
    "#                       sel_cpen[ts][0],\n",
    "#                       sel_cpent[ts][0], \n",
    "#                       sel_ratem[ts][0]    trk_em/ sim_em\n",
    "#                       sel_rattot[ts][0]   trk/sim\n",
    "#                        )).T\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, datapath, numLC, feats, signal, ispi, abz):\n",
    "        self.datapath_ = datapath\n",
    "        self.numLC_ = numLC\n",
    "        self.signal_ = signal\n",
    "        self.ispi_ = ispi\n",
    "        self.abz_ = abz\n",
    "        self.feats_ = feats\n",
    "        self.process = self.load_datafiles(self.datapath_)\n",
    "        self.data = torch.stack(self.process[0],dim=0)\n",
    "        self.labels = torch.stack(self.process[1],dim=0)\n",
    "        self.masks = torch.stack(self.process[2],dim=0)\n",
    "        self.info3d = torch.stack(self.process[3],dim=0)\n",
    "        self.infogun = torch.stack(self.process[4],dim=0)\n",
    "\n",
    "\n",
    "    def load_datafiles(self, filepath) :\n",
    "        \"filepath of the form /grid_mnt/data__data.polcms/cms/sghosh/NEWPID_DATA/ntup_pho_frac0p8/ \"\n",
    "        print(\"processing files from:\",filepath)\n",
    "        filelist = [filen for filen in glob.glob(filepath+'data*.pt')]\n",
    "        output_tensor_list = []\n",
    "        label = []\n",
    "        mask_tensor_list = []\n",
    "        info3d_tensor_list = []\n",
    "        infogun_tensor_list = []\n",
    "        \n",
    "        ctot = 0\n",
    "        cll = 0\n",
    "        \n",
    "        \n",
    "        for i in tqdm(filelist):\n",
    "            if (len(label)>50000):\n",
    "                    break\n",
    "            \n",
    "            for filei in torch.load(i) :\n",
    "                ctot += 1\n",
    "                #print(filei.gun_feat)\n",
    "                passpi = False\n",
    "                passpu = False\n",
    "                nlay = len(np.unique(filei.clus2d_feat[:,5]))\n",
    "                ratrec_true = (filei.clus3d_feat[2]/filei.gun_feat[:,3]).item()\n",
    "\n",
    "                if (self.signal_):\n",
    "#                    if (nlay < 13) :\n",
    "                    if (ratrec_true < 0.7):\n",
    "                        cll += 1                        \n",
    "                        continue\n",
    "                else:\n",
    "                    feat2da = filei.clus2d_feat\n",
    "                    fracen26 = torch.sum(feat2da[feat2da[:,5] <=26][:,3])/torch.sum(feat2da[:,3])\n",
    "                    if self.ispi_:\n",
    "                        #if (nlay > 10)and(fracen26 > 0.7)and(min(feat2da[:,5]) < 15) :\n",
    "                        passpi = True\n",
    "                        if not(passpi):\n",
    "                            cll += 1\n",
    "                            continue\n",
    "                        #print(\"self.ispi_ & nlay < 10 & fracen26< 0.7\", self.ispi_, nlay , fracen26)\n",
    "                    else:\n",
    "                        #if ((nlay < 10)and(fracen26 < 0.7))or ((nlay > 10)and(fracen26 < 0.7)) or ((nlay < 10)and(fracen26 > 0.7)):\n",
    "                        #if not((nlay > 10)and(fracen26 > 0.7)and(min(feat2da[:,5]) < 15)):\n",
    "                        if not((nlay > 10)and(fracen26 > 0.6)and(min(feat2da[:,5]) < 15)and((np.average(filei.clus2d_feat[:,2], weights=filei.clus2d_feat[:,3])) < 360)):\n",
    "                            passpu = True\n",
    "                        else:\n",
    "                            pass\n",
    "                            #print(\"self.ispi_ & nlay < 10 & fracen26< 0.7\", self.ispi_, nlay, fracen26)\n",
    "                        if not(passpu):\n",
    "                            cll += 1\n",
    "                            continue\n",
    "                        #print(\"self.ispi_ & nlay < 10 & fracen26< 0.7\", self.ispi_, nlay, fracen26)\n",
    "               \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                optensor = self.transform_data(filei.clus2d_feat, self.numLC_)\n",
    "                output_tensor_list.append(optensor[0])\n",
    "                mask_tensor_list.append(optensor[1])\n",
    "                info3d_tensor_list.append(filei.clus3d_feat[[0,1,2,4,5]])\n",
    "                infogun_tensor_list.append(filei.gun_feat)\n",
    "                if self.signal_:\n",
    "                    label.append(torch.ones(1,dtype=torch.double))\n",
    "                else:\n",
    "                    label.append(torch.zeros(1,dtype=torch.double))\n",
    "         \n",
    "        \n",
    "        print (\"nskipped | ntotal:\",cll,\" | \",ctot)\n",
    "        return output_tensor_list, label, mask_tensor_list, info3d_tensor_list, infogun_tensor_list\n",
    "                \n",
    "    def transform_data(self, tensor, nLC) :            \n",
    "\n",
    "        #feats = [0,1,2,5]\n",
    "        target = torch.zeros(nLC, len(self.feats_))\n",
    "        mask0 = torch.ones(nLC)\n",
    "        source = tensor[:nLC,self.feats_]\n",
    "        mask1 = torch.zeros(source.shape[0])\n",
    "        if self.abz_:\n",
    "            source[:,2] = np.abs(source[:,2])\n",
    "        target[:source.shape[0], :] = source\n",
    "        #source = source.T\n",
    "        mask0[:source.shape[0]] = mask1\n",
    "        mask0 \n",
    "        #print(mask0)\n",
    "        return target, mask0 > 0\n",
    "    \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return self.data[idx], self.labels[idx], self.masks[idx], self.info3d[idx], self.infogun[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pho_path = \"/grid_mnt/data__data.polcms/cms/sghosh/NEWPID_TICLDUMPER_DATA/S2Rmin_pho_30072024/\"\n",
    "pho_dataset = ClassificationDataset(pho_path, 150, [0,1,5,3], True, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hizpu_path = \"/grid_mnt/data__data.polcms/cms/sghosh/NEWPID_TICLDUMPER_DATA/S2R0p9_pi_30072024/\"\n",
    "hizpu_dataset = ClassificationDataset(hizpu_path, 150, [0,1,5,3], False, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowzpu_path = \"/grid_mnt/data__data.polcms/cms/sghosh/NEWPID_TICLDUMPER_DATA/S2Rno_PUenrich_05082024/\"\n",
    "lowzpu_dataset = ClassificationDataset(lowzpu_path, 150, [0,1,5,3], False, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lenpho:\",len(pho_dataset), \" lenhizpu:\",len(hizpu_dataset), \" lenlozpu:\",len(lowzpu_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nphos = len(pho_dataset)\n",
    "idxstotsamp = np.arange(nphos)\n",
    "hizpusel = torch.utils.data.Subset(hizpu_dataset, idxstotsamp[:int(0.3*nphos)])\n",
    "lowzpusel = torch.utils.data.Subset(lowzpu_dataset, idxstotsamp[:int(0.7*nphos)])\n",
    "#npusel = len(pho_dataset) - len(pisel)\n",
    "#pusel = torch.utils.data.Subset(pu_dataset, idxstotsamp[:int(npusel)])\n",
    "\n",
    "combdataset = torch.utils.data.ConcatDataset([pho_dataset, hizpusel, lowzpusel])\n",
    "\n",
    "nsamp = len(combdataset)\n",
    "\n",
    "idxs = np.arange(nsamp)\n",
    "np.random.shuffle(idxs)\n",
    "tridx = idxs[:int(0.8*nsamp)]\n",
    "tsidx = idxs[int(0.8*nsamp):nsamp]\n",
    "trdata = torch.utils.data.Subset(combdataset, tridx)\n",
    "tsdata = torch.utils.data.Subset(combdataset, tsidx)\n",
    "\n",
    "ntrainbatch = 600\n",
    "trainloader = torch.utils.data.DataLoader(trdata, batch_size=ntrainbatch ,shuffle=True)#, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(tsdata, batch_size=ntrainbatch,shuffle=True)#, num_workers=2)\n",
    "\n",
    "\n",
    "print(\"total samples > npho | nhizpu | nlozpu | nTOT:\",len(pho_dataset),\" | \",len(hizpusel),\" | \",len(lowzpusel),\" | \",nsamp)\n",
    "print(\"N_train, N_test:\",len(trdata),\",\",len(tsdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22264./(22264.+27617.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model\n",
    "## refer https://github.com/ludovicobuizza/HAR-Transformer/blob/main/src/transformer/transformer.py for batchnorm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MHA_model(jit.ScriptModule):\n",
    "    \n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim = 6,\n",
    "        dim_emb = 64,\n",
    "        n_heads = 16,\n",
    "        num_enclayers = 6,\n",
    "        dim_feedforward = 64,\n",
    "        n_seq = 150,\n",
    "        output_dim = 2,\n",
    "        norm=torch.tensor([1./100., 1./100., 1./100., 1./100.]),\n",
    "    ):\n",
    "        \n",
    "        super(MHA_model, self).__init__()\n",
    "        self.datanorm = nn.Parameter(norm, requires_grad=False) \n",
    "        self.emb_inp = nn.Sequential(\n",
    "            nn.Linear(input_dim, dim_emb),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ELU(),\n",
    "            #nn.LeakyReLU(negative_slope=0.4),\n",
    "            nn.Linear(dim_emb, dim_emb),\n",
    "            nn.Dropout(0.2),\n",
    "#            nn.LeakyReLU(negative_slope=0.4),\n",
    "#            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            #nn.LeakyReLU(negative_slope=0.4),\n",
    "        )\n",
    "        \n",
    "#        self.emb_inp =  nn.Linear(input_dim, dim_emb)      \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "                dim_emb,\n",
    "                n_heads,\n",
    "                dim_feedforward,\n",
    "                dropout = 0.2,\n",
    "                batch_first= True,\n",
    "                activation=nn.ELU(),  #nn.LeakyReLU(negative_slope=0.4),\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_enclayers)\n",
    "        \n",
    "        self.output_layer = nn.Sequential(nn.Linear(n_seq*dim_emb + 5, dim_emb//2),\n",
    "                                    \n",
    "                                    #nn.LeakyReLU(negative_slope=0.4),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.ELU(),\n",
    "                                    #nn.Softplus(),\n",
    "                                    nn.Linear(dim_emb//2, dim_emb//2),#added\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.ELU(),\n",
    "                                    nn.Linear(dim_emb//2, dim_emb//2),#added\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.ELU(),\n",
    "                                    #nn.Softplus(),\n",
    "                                    nn.Linear(dim_emb//2, output_dim)\n",
    "                                   )\n",
    "    \n",
    "    \n",
    "    @jit.script_method\n",
    "    def forward(self, X, mask, info3d) :\n",
    "        \n",
    "        \n",
    "        #project input to dim_emb dimensional space\n",
    "        X = self.datanorm*X\n",
    "        inp = self.emb_inp(X) #* math.sqrt(self.dim_embed)\n",
    "        \n",
    "        output = self.transformer_encoder(inp, src_key_padding_mask=mask)  # (batch, seq, feat)\n",
    "        output = output.reshape(output.shape[0], -1)  # (batch, seq * feat)\n",
    "        output = torch.concat((output,info3d), dim = -1)\n",
    "        output = self.output_layer(output)  # (batch, num_classes)\n",
    "\n",
    "        return F.log_softmax(output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define training and testing functions\n",
    "#from lr_modulation import *\n",
    "device = torch.device('cuda:0')#('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "#model = NetCNN().to(float) ### change to NetDNN().to(float) for DNN\n",
    "#model = model.to(device)\n",
    "\n",
    "\n",
    "model = MHA_model(n_seq=150,\n",
    "        input_dim = 4,\n",
    "        dim_emb = 16,#32\n",
    "        n_heads = 16,\n",
    "        num_enclayers = 6,#4\n",
    "        dim_feedforward = 64,\n",
    "        output_dim = 2)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "#scheduler = CyclicLRWithRestarts(optimizer, ntrainbatch, epoch_size, restart_period=10, t_mult=1.2, policy=\"cosine\")\n",
    "#scheduler = CyclicLRWithRestarts(optimizer, 200, 200, restart_period=30, t_mult=1.2, policy=\"cosine\")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,50)\n",
    "#lossfunction = nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    loss = []\n",
    "    true_preds, num_preds = 0., 0.\n",
    "    iters = len(trainloader)\n",
    "    cc = 0\n",
    "    for data in tqdm(trainloader):  ### change to loaderDNN for DNN\n",
    "            #datax, label = data[0].to(device), data[1].to(device)\n",
    "            datax, label, masks, info3d = data[0].to(device), data[1].to(device), data[2].to(device), data[3].to(device)\n",
    "            label = label.to(torch.long).squeeze()\n",
    "            optimizer.zero_grad()\n",
    "            result = model(datax, masks, info3d)\n",
    "            #print(result)\n",
    "            \n",
    "            #print(label)\n",
    "            #print(result.dtype)\n",
    "            #lossc = lossfunction(result, label)\n",
    "            lossc = F.nll_loss(result, label)\n",
    "            \n",
    "            loss.append(lossc.item()) \n",
    "            lossc.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(epoch + cc / iters)\n",
    "            cc += 1\n",
    "            pred_labels = torch.argmax(result.cpu(), dim=-1) \n",
    "            true_preds += (pred_labels == label.cpu()).sum()\n",
    "            num_preds += label.shape[0]\n",
    "            \n",
    "    acc = true_preds / num_preds\n",
    "    #print( 'batches for train:',len(loss)) \n",
    "    print('train loss:',np.mean(np.array(loss)))\n",
    "    print('train acc:',np.mean(np.array(acc)))\n",
    "    return np.mean(np.array(loss)), np.array(acc)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    loss = []\n",
    "    true_preds, num_preds = 0., 0.\n",
    "    for data in tqdm(testloader): ### change to loaderDNN for DNN\n",
    "            datax, label, masks, info3d = data[0].to(device), data[1].to(device), data[2].to(device), data[3].to(device)            \n",
    "            label = label.to(torch.long).squeeze()\n",
    "            result = model(datax, masks, info3d)\n",
    "            lossc = F.nll_loss(result, label)\n",
    "            loss.append(lossc.item())\n",
    "            \n",
    "            pred_labels = torch.argmax(result.cpu(), dim=-1) \n",
    "            true_preds += (pred_labels == label.cpu()).sum()\n",
    "            num_preds += label.shape[0]\n",
    "            \n",
    "            \n",
    "    acc = true_preds / num_preds\n",
    "    #print( 'batches for train:',len(loss)) \n",
    "    print('test loss:',np.mean(np.array(loss)))\n",
    "    print('test acc:',np.mean(np.array(acc)))\n",
    "    return np.mean(np.array(loss)), np.array(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "\n",
    "checkpoint_dir =\"/home/llr/cms/sghosh/RedoID/training_scripts/MODELS/OUTPUTDIR\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "nepoch=500\n",
    "best_loss = 99999999\n",
    "best_acc = 0.\n",
    "losst = []\n",
    "lossv = []\n",
    "acct = []\n",
    "accv = []\n",
    "epochs = []\n",
    "for epoch in range(nepoch):\n",
    "    print ('epoch:',epoch)\n",
    "    print(\"Learning rate:\", optimizer.param_groups[0]['lr'])\n",
    "    loss_t, acc_t = train(epoch)\n",
    "    losst.append(loss_t)\n",
    "    acct.append(acc_t)\n",
    "    loss_v, acc_v = test(epoch)\n",
    "    loss_epoch = loss_v\n",
    "    lossv.append(loss_epoch)\n",
    "    accv.append(acc_v)\n",
    "    epochs.append(epoch)\n",
    "\n",
    "    \n",
    "     \n",
    "    \n",
    "    checkpoint = {\n",
    "    'epoch': epoch + 1,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    checkpoint_file = 'model_epoch_%i.pth.tar' % ( epoch )\n",
    "    torch.save(checkpoint,\n",
    "                   os.path.join(checkpoint_dir,checkpoint_file ))\n",
    "    \n",
    "#     if loss_epoch < best_loss:\n",
    "#         best_loss = loss_epoch\n",
    "#         print('new best test loss:',best_loss)\n",
    "#         torch.save(checkpoint,\n",
    "#                    os.path.join(checkpoint_dir,'model_checkpoint_best.pth.tar' ))\n",
    "    \n",
    "    \n",
    "    if acc_v > best_acc:\n",
    "        print('new best acc:',acc_v)\n",
    "        best_acc = acc_v\n",
    "        torch.save(checkpoint,\n",
    "                   os.path.join(checkpoint_dir,'model_checkpoint_bestacc.pth.tar' ))\n",
    "    \n",
    "    if ((epoch+1)%10 == 0):\n",
    "        fig, (ax0,ax1) = plt.subplots(1,2,figsize=(10, 6),dpi=80)\n",
    "        \n",
    "        ax0.plot(np.array(epochs),np.array(losst),c='b',label='training')\n",
    "        ax0.plot(np.array(epochs),np.array(lossv),c='r',label='testing')\n",
    "        ax0.title.set_text(\"loss\")\n",
    "        #if ((epoch+1) == nepoch):\n",
    "        #    plt.savefig('%s/TrainvsValLoss_ep%d.png'%(plot_dir, epoch), bbox_inches='tight')\n",
    "        #plt.legend()\n",
    "        #plt.show()\n",
    "        ax1.plot(np.array(epochs),np.array(acct),c='b',label='training')\n",
    "        ax1.plot(np.array(epochs),np.array(accv),c='r',label='testing')\n",
    "        ax1.title.set_text(\"accuracy\")\n",
    "        plt.legend()\n",
    "        #if ((epoch+1) == nepoch):\n",
    "        #    plt.savefig('%s/TrainvsValLoss_ep%d.png'%(plot_dir, epoch), bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        scores = []\n",
    "        trues = []\n",
    "        true_preds, num_preds = 0., 0.\n",
    "        for data in tqdm(testloader): ### change to loaderDNN for DNN\n",
    "                datax, label, masks, info3d = data[0].to(device), data[1].to(device), data[2].to(device), data[3].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                #label = label.to(torch.long).squeeze()\n",
    "                result = model(datax, masks, info3d)\n",
    "                scores.append(torch.exp(result)[:,1].detach().cpu().flatten().numpy())\n",
    "                trues.append(label.detach().cpu().numpy().flatten())\n",
    "        \n",
    "        \n",
    "        truesa = np.hstack(trues)\n",
    "        scoresa = np.hstack(scores)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(truesa, scoresa, pos_label=1)\n",
    "        aucv = metrics.auc(fpr, tpr)\n",
    "\n",
    "        tpr90,fpr90,threshold90 = 0,0,0\n",
    "        for i,j,k in zip(tpr,fpr,thresholds):\n",
    "            if i >0.99:\n",
    "                tpr90 = i\n",
    "                fpr90 = j\n",
    "                threshold90 = k\n",
    "                break\n",
    "\n",
    "        fig, (ax0,ax1) = plt.subplots(1,2,figsize=(10, 6),dpi=80)\n",
    "        plt.rcParams['font.size'] = '14'\n",
    "        ax0.plot(tpr,fpr, linewidth=7.0, label= \"AUC:\"+str(round(aucv,3))+\" eff:\"+str(round(tpr90,3))+\" @ bkg rejection rate:\"+str(round(1-fpr90,3)))\n",
    "        ax0.set_xlabel(\"signal efficiency\")\n",
    "        ax0.set_ylabel(\"mistag rate\")\n",
    "        ax0.set_xlim([0.5,1])\n",
    "        ax0.plot([0.,1], [0.,1], 'k--')\n",
    "        ax0.title.set_text(\"test\")\n",
    "        plt.legend()\n",
    "        #ax.text(0.6,0.6,aucv,)\n",
    "        #plt.yscale(\"log\")\n",
    "        \n",
    "        ax1.hist(scoresa[truesa == 1],bins=100, range=[0,1.01], label='photons',linewidth=2.0, color=\"r\" , alpha=0.3)\n",
    "        ax1.hist(scoresa[truesa == 0],bins=100, range=[0,1.01], label='bkgs',linewidth=2.0, color=\"b\", alpha=0.3 )\n",
    "        ax1.axvline(threshold90,c=\"b\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ConfusionMatrixDisplay.from_predictions(np.hstack(trues), np.where(np.hstack(scores)>threshold90, 1, 0))\n",
    "        plt.show()\n",
    "        ConfusionMatrixDisplay.from_predictions(np.hstack(trues), np.where(np.hstack(scores)>threshold90, 1, 0), normalize=\"true\")\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "scores = []\n",
    "trues = []\n",
    "true_preds, num_preds = 0., 0.\n",
    "for data in tqdm(testloader): ### change to loaderDNN for DNN\n",
    "        datax, label, masks, info3d = data[0].to(device), data[1].to(device), data[2].to(device), data[3].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #label = label.to(torch.long).squeeze()\n",
    "        result = model(datax, masks, info3d)\n",
    "        scores.append(torch.exp(result)[:,1].detach().cpu().flatten().numpy())\n",
    "        trues.append(label.detach().cpu().numpy().flatten())\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np.hstack(trues), np.hstack(scores), pos_label=1)\n",
    "aucv = metrics.auc(fpr, tpr)\n",
    "\n",
    "tpr90,fpr90,threshold90 = 0,0,0\n",
    "for i,j,k in zip(tpr,fpr,thresholds):\n",
    "    if i >0.99:\n",
    "        tpr90 = i\n",
    "        fpr90 = j\n",
    "        threshold90 = k\n",
    "        break\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6),dpi=80)\n",
    "plt.rcParams['font.size'] = '14'\n",
    "ax.plot(tpr,fpr, linewidth=7.0, label= \"AUC:\"+str(round(aucv,3))+\" eff:\"+str(round(tpr90,3))+\" @ bkg rejection rate:\"+str(round(1-fpr90,3)))\n",
    "ax.set_xlabel(\"signal efficiency\")\n",
    "ax.set_ylabel(\"mistag rate\")\n",
    "ax.set_xlim([0.5,1])\n",
    "ax.plot([0.,1], [0.,1], 'k--')\n",
    "ax.title.set_text(\"test\")\n",
    "#ax.text(0.6,0.6,aucv,)\n",
    "#plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "#confusion_matrix(np.hstack(trues), np.where(np.hstack(scores)>0.5, 1, 0))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(np.hstack(trues), np.where(np.hstack(scores)>threshold90, 1, 0))\n",
    "plt.show()\n",
    "ConfusionMatrixDisplay.from_predictions(np.hstack(trues), np.where(np.hstack(scores)>threshold90, 1, 0), normalize=\"true\")\n",
    "plt.show()\n",
    "ConfusionMatrixDisplay.from_predictions(np.hstack(trues), np.where(np.hstack(scores)>threshold90, 1, 0), normalize=\"pred\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llrenv",
   "language": "python",
   "name": "llrenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
